# ========= Global configuration ========== #
logging_step: 25
# ========= Global configuration ========== #

# some train configuration, more can be found under dsconfig folder
seed: 0
warmup_rate: 0.1
epochs: 1
max_shard_size: 10GB

# deepspeed arguments
deepspeed:
  train_batch_size: 256
  train_micro_batch_size_per_gpu: 256
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  steps_per_print: 1

  zero_optimization:
    allgather_bucket_size: 500000000
    allgather_partitions: true
    contiguous_gradients: true
    offload_optimizer:
      device: cpu
    stage: 1

  optimizer:
    type: Adam
    params:
      betas:
      - 0.9
      - 0.95
      eps: 1.0e-08
      lr: 1.6e-3
      weight_decay: 0
      #gradient_clipping: 1.0
    
  scheduler:
    type: WarmupDecayLR
    params:
      total_num_steps: 20000
      warmup_max_lr: 1.6e-3
      warmup_min_lr: 0
      warmup_num_steps: 100

  fp16:
    enabled: false
    #min_loss_scale: 1
    #opt_level: O2
  
  bf16:
    enabled: true
    min_loss_scale: 1
    opt_level: O2

  activation_checkpointing:
    partition_activations: true
    cpu_checkpointing: true
    contiguous_memory_optimization: false
    number_checkpoints: null
    synchronize_checkpoint_boundary: false
    profile: false
